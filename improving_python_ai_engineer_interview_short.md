# Python + AI Engineer Interview - Short Version
## Quick Refresh Guide

---

# ðŸŸ¢ LLM Fundamentals

## 1. Ð¢Ð¾ÐºÐµÐ½Ñ‹
- **Ð¢Ð¾ÐºÐµÐ½** â‰ˆ 4 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð° / 0.75 ÑÐ»Ð¾Ð²Ð°
- ÐžÐ¿Ð»Ð°Ñ‚Ð°: input + output (Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ñ†ÐµÐ½Ñ‹)
- `tiktoken` Ð´Ð»Ñ Ð¿Ð¾Ð´ÑÑ‡Ñ‘Ñ‚Ð°

## 2. Context Window
- GPT-4o: 128K, Claude: 200K, Gemini: 2M
- **Lost in the Middle** â€” Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ…ÑƒÐ¶Ðµ Ð¿Ð¾Ð¼Ð½Ð¸Ñ‚ ÑÐµÑ€ÐµÐ´Ð¸Ð½Ñƒ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
- Ð’Ð°Ð¶Ð½Ð¾Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ‰Ð°Ñ‚ÑŒ Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ/ÐºÐ¾Ð½Ñ†Ðµ

## 3. Temperature
- `0` â€” Ð´ÐµÑ‚ÐµÑ€Ð¼Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ (extraction, classification)
- `0.3-0.5` â€” ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ (Q&A)
- `0.7-1.0` â€” ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ (writing)

## 4. Embeddings
- Ð’ÐµÐºÑ‚Ð¾Ñ€ Ñ‚ÐµÐºÑÑ‚Ð° Ð² Ð¼Ð½Ð¾Ð³Ð¾Ð¼ÐµÑ€Ð½Ð¾Ð¼ Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²Ðµ
- ÐŸÐ¾Ñ…Ð¾Ð¶Ð¸Ðµ Ñ‚ÐµÐºÑÑ‚Ñ‹ â†’ Ð±Ð»Ð¸Ð·ÐºÐ¸Ðµ Ð²ÐµÐºÑ‚Ð¾Ñ€Ñ‹
- Cosine similarity Ð´Ð»Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ
- `text-embedding-3-large` (3072 dims)

## 5. Streaming
- Ð£Ð»ÑƒÑ‡ÑˆÐ°ÐµÑ‚ UX, ÑÐ½Ð¸Ð¶Ð°ÐµÑ‚ perceived latency
- OpenAI: `stream=True`, iterate `chunk.choices[0].delta.content`
- Anthropic: `client.messages.stream()`, iterate `stream.text_stream`

## 6. Structured Output
- **JSON mode**: `response_format={"type": "json_object"}`
- **Function calling**: `response_format=PydanticModel` (OpenAI)
- **Anthropic**: `tools` + `tool_choice` Ð´Ð»Ñ structured output

## 7. Azure vs OpenAI vs Anthropic
| | Azure | OpenAI | Anthropic |
|-|-------|--------|-----------|
| Enterprise | âœ… SOC2, HIPAA | âš ï¸ | âœ… SOC2 |
| Data residency | âœ… | âŒ | âŒ |
| SLA | âœ… 99.9% | âŒ | âŒ |

---

# ðŸŸ¡ RAG & Vector Search

## 8. RAG Architecture
```
Query â†’ Embedding â†’ Vector Search â†’ Top-K â†’ Rerank â†’ LLM â†’ Answer
```

## 9. Chunking
- **Fixed size**: Ð¿Ñ€Ð¾ÑÑ‚Ð¾, Ñ€ÐµÐ¶ÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
- **Recursive**: ÑƒÐ²Ð°Ð¶Ð°ÐµÑ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ (\n\n, \n, .)
- **Semantic**: Ð¿Ð¾ ÑÐ¼Ñ‹ÑÐ»Ñƒ (Ð´Ð¾Ñ€Ð¾Ð¶Ðµ, Ð»ÑƒÑ‡ÑˆÐµ)
- Overlap 10-20% Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°

## 10. Azure AI Search
- **Hybrid search** = vector + keyword
- `VectorizedQuery` + `search_text`
- HNSW Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ Ð´Ð»Ñ vector index

## 11. Reranking
- Vector search â†’ Top 50 (recall)
- Reranker (cross-encoder) â†’ Top 5 (precision)
- Cohere Rerank / Azure Semantic Ranker

## 12. Retrieval Metrics
- **Precision@K**: relevant Ð² top-K / K
- **Recall@K**: Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ relevant / Ð²ÑÐµÐ³Ð¾ relevant
- **MRR**: 1 / Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ñ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ relevant

---

# ðŸŸ  Agentic AI & Pydantic AI

## 13. Agent vs Chatbot vs Copilot
- **Chatbot**: Qâ†’A, Ð±ÐµÐ· tools
- **Copilot**: suggestions, user approves
- **Agent**: Ð°Ð²Ñ‚Ð¾Ð½Ð¾Ð¼Ð½Ñ‹Ð¹, multi-step, tools

## 14. Pydantic AI Basics
```python
agent = Agent("openai:gpt-4o", result_type=MyModel)
result = agent.run_sync("query")
```

## 15. Dependencies (DI)
```python
@dataclass
class Deps:
    db: Database
    user_id: str

agent = Agent("openai:gpt-4o", deps_type=Deps)

@agent.tool
async def get_data(ctx: RunContext[Deps]) -> str:
    return await ctx.deps.db.query(ctx.deps.user_id)
```

## 16. Tools
```python
@agent.tool
async def my_tool(ctx: RunContext[Deps], param: str = Field(description="...")) -> str:
    return result
```
- `prepare=` Ð´Ð»Ñ dynamic enable/disable
- `require_confirmation=True` Ð´Ð»Ñ Ð¾Ð¿Ð°ÑÐ½Ñ‹Ñ…

## 17. ReAct Pattern
```
Thought â†’ Action â†’ Observation â†’ Thought â†’ ... â†’ Answer
```
Ð§ÐµÑ€ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ reasoning Ð¸ tool calls.

## 18. Function Calling: OpenAI vs Anthropic
| | OpenAI | Anthropic |
|-|--------|-----------|
| Response | `tool_calls` array | `tool_use` blocks |
| Args | JSON string (parse!) | Already dict |
| Result | `role: "tool"` | `tool_result` in user msg |

## 19. Multi-Agent Patterns
- **Sequential**: A â†’ B â†’ C
- **Hierarchical**: Manager delegates to Workers
- **Debate**: Pro vs Con â†’ Judge

## 20. Agent Memory
- **Short-term**: `message_history=result.all_messages()`
- **Long-term**: Vector DB Ñ memories, retrieve Ð¿Ð¾ query

## 21. Model Settings
```python
agent = Agent("openai:gpt-4o", retries=3, model_settings=ModelSettings(temperature=0))
```

## 22. Structured Output
```python
class Result(BaseModel):
    answer: str
    confidence: float = Field(ge=0, le=1)

agent = Agent("openai:gpt-4o", result_type=Result)
```

---

# ðŸ”´ Production AI Systems

## 23. Observability (Logfire)
```python
logfire.configure()
logfire.instrument_pydantic_ai()
```
Track: latency, tokens, cost, errors

## 24. Prompt Injection Protection
- Input sanitization (regex patterns)
- Structured output (Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÑ‚ actions)
- Data/instruction separation Ð² Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ðµ
- Output validation

## 25. Hallucination Mitigation
- Grounded generation (only from context)
- Require supporting quotes
- Self-consistency (multiple samples)
- Citation verification

## 26. Rate Limiting & Cost
- Track requests/min, tokens/min
- Cost = input_tokens Ã— price + output_tokens Ã— price
- Per-user limits

## 27. Caching
- **Exact cache**: hash(prompt) â†’ response
- **Semantic cache**: similar embeddings â†’ cached response
- **Prompt caching** (Anthropic): `cache_control: ephemeral` â†’ 90% discount

## 28. When to Use What
| Approach | Use Case |
|----------|----------|
| RAG | Factual Q&A, docs, fresh data |
| Agents | Multi-step, tools, dynamic |
| Fine-tuning | Consistent style, domain terms |
| Prompts | Quick iteration, flexible |

## 29. Error Handling
- Retry + exponential backoff
- Fallback models (gpt-4o â†’ gpt-4o-mini)
- Circuit breaker (N failures â†’ stop calling)

## 30. Testing
```python
# Mock model
agent = Agent(TestModel())

# Eval dataset
@pytest.mark.parametrize("case", eval_cases)
async def test_eval(case):
    result = await agent.run(case["input"])
    assert keyword in result.data
```

## 31. Streaming
```python
async with agent.run_stream("query") as response:
    async for chunk in response.stream_text():
        print(chunk, end="")
```

## 32. Multi-model Routing
- Classifier (cheap) â†’ route to specialist (expensive)
- Simple â†’ gpt-4o-mini, Complex â†’ gpt-4o, Code â†’ Claude

## 33. Azure Patterns
- **Managed Identity**: `DefaultAzureCredential()`
- **Multi-region failover**: list of endpoints
- **AI Search integration**: hybrid search + semantic ranker

## 34. Advanced Pydantic AI
- `@agent.result_validator` â€” quality control
- `@agent.system_prompt` â€” dynamic prompts
- `Union[Success, Error, NeedInfo]` â€” multiple outcomes

## 35. Production Checklist
- âœ… Input validation, prompt injection protection
- âœ… Retry logic, circuit breaker, fallbacks
- âœ… Rate limiting, cost tracking, caching
- âœ… Logging, metrics, alerts
- âœ… Eval dataset, testing pipeline

---

# Quick Reference

```python
# Basic
agent = Agent("openai:gpt-4o", result_type=Output, deps_type=Deps)
result = await agent.run("query", deps=deps)

# Tool
@agent.tool
async def tool(ctx: RunContext[Deps], param: str) -> str:
    return ctx.deps.db.query(param)

# History
result2 = await agent.run("q2", message_history=result1.all_messages())

# Stream
async with agent.run_stream("q") as r:
    async for chunk in r.stream_text():
        print(chunk)
```

---

*Good luck!*
